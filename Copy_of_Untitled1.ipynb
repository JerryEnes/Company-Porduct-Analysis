import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from PIL import Image
from transformers import ViTFeatureExtractor, ViTModel
import timm
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# --- CONSTANTS ---
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 50
PATIENCE = 5
SEED = 42
DATASET_PATH = "/content/drive/MyDrive/Multimodal Biometric 3"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- TRANSFORMS ---
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# --- DATASET ---
class MultiModalDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.samples = []
        self.transform = transform
        self.class_to_idx = {}
        for idx, class_name in enumerate(sorted(os.listdir(root_dir))):
            self.class_to_idx[class_name] = idx
            class_path = os.path.join(root_dir, class_name)
            iris_dir = os.path.join(class_path, 'iris-eye')
            vein_dir = os.path.join(class_path, 'finger-vein')
            iris_imgs = sorted(os.listdir(iris_dir))
            vein_imgs = sorted(os.listdir(vein_dir))
            for i in range(min(len(iris_imgs), len(vein_imgs))):
                self.samples.append({
                    'iris': os.path.join(iris_dir, iris_imgs[i]),
                    'vein': os.path.join(vein_dir, vein_imgs[i]),
                    'label': idx
                })

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        sample = self.samples[idx]
        iris = Image.open(sample['iris']).convert('RGB')
        vein = Image.open(sample['vein']).convert('RGB')
        label = sample['label']

        if self.transform:
            iris = self.transform(iris)
            vein = self.transform(vein)

        return iris, vein, label

# --- MODEL ---
class MultiModalFusionModel(nn.Module):
    def __init__(self, num_classes):
        super().__init__()

        self.iris_model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=num_classes)
        self.vein_model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=num_classes)

        self.feature_extractor_iris = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=0)
        self.feature_extractor_vein = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=0)

        self.feature_fusion = nn.Sequential(
            nn.Linear(192 * 2, 1024),
            nn.GELU(), nn.BatchNorm1d(1024), nn.Dropout(0.3),
            nn.Linear(1024, 1024), nn.ReLU(), nn.BatchNorm1d(1024), nn.Dropout(0.3),
            nn.Linear(1024, 512), nn.GELU(), nn.BatchNorm1d(512), nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

        self.score_fusion_layer = nn.Sequential(
            nn.Linear(num_classes * 2, 512),
            nn.GELU(), nn.BatchNorm1d(512), nn.Dropout(0.4),
            nn.Linear(512, 256), nn.GELU(), nn.BatchNorm1d(256), nn.Dropout(0.3),
            nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.2),
            nn.Linear(128, num_classes)
        )

    def forward(self, iris, vein, return_all=False):
        score_iris = self.iris_model(iris)
        score_vein = self.vein_model(vein)
        score_concat = torch.cat((score_iris, score_vein), dim=1)
        score_fusion = self.score_fusion_layer(score_concat)

        feat_iris = self.feature_extractor_iris(iris)
        feat_vein = self.feature_extractor_vein(vein)
        feat_fusion = torch.cat((feat_iris, feat_vein), dim=1)
        feat_output = self.feature_fusion(feat_fusion)

        final_output = 0.6 * score_fusion + 0.4 * feat_output

        if return_all:
            return final_output, score_fusion, feat_output
        return final_output

# --- TRAINING ---
def train_model(model, train_loader, val_loader, device):
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)

    best_val_acc = 0
    patience_counter = 0
    train_accuracies, val_accuracies = [], []

    model.to(device)

    for epoch in range(EPOCHS):
        model.train()
        train_acc = 0
        for iris, vein, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
            iris, vein, labels = iris.to(device), vein.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(iris, vein)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_acc += accuracy_score(labels.cpu(), outputs.argmax(dim=1).cpu())

        model.eval()
        val_acc = 0
        with torch.no_grad():
            for iris, vein, labels in val_loader:
                iris, vein, labels = iris.to(device), vein.to(device), labels.to(device)
                outputs = model(iris, vein)
                val_acc += accuracy_score(labels.cpu(), outputs.argmax(dim=1).cpu())

        avg_train_acc = train_acc / len(train_loader)
        avg_val_acc = val_acc / len(val_loader)

        train_accuracies.append(avg_train_acc)
        val_accuracies.append(avg_val_acc)

        scheduler.step(avg_val_acc)

        print(f"Epoch {epoch+1} | Train Acc: {avg_train_acc:.4f} | Val Acc: {avg_val_acc:.4f}")

        if avg_val_acc > best_val_acc:
            best_val_acc = avg_val_acc
            patience_counter = 0
            torch.save(model.state_dict(), 'best_model.pt')
            print("âœ… Best model saved")
        else:
            patience_counter += 1
            if patience_counter >= PATIENCE:
                print("ðŸ›‘ Early stopping triggered")
                break

    # Plot training curves
    plt.plot(train_accuracies, label="Train Accuracy")
    plt.plot(val_accuracies, label="Val Accuracy")
    plt.title("Accuracy over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.grid(True)
    plt.show()

# --- CONFUSION MATRIX PLOT ---
def plot_conf_matrix(y_true, y_pred, title="Confusion Matrix"):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(title)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

# --- METRICS ---
def print_metrics(y_true, y_pred, label=""):
    print(f"\nðŸ“Š {label} Metrics")
    print(f"Accuracy:  {accuracy_score(y_true, y_pred):.4f}")
    print(f"Precision: {precision_score(y_true, y_pred, average='macro'):.4f}")
    print(f"Recall:    {recall_score(y_true, y_pred, average='macro'):.4f}")
    print(f"F1 Score:  {f1_score(y_true, y_pred, average='macro'):.4f}")
    plot_conf_matrix(y_true, y_pred, f"{label} Confusion Matrix")

# --- LOAD DATA ---
dataset = MultiModalDataset(DATASET_PATH, transform)
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_set, val_set = random_split(dataset, [train_size, val_size])
train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)

# --- TRAIN ---
model = MultiModalFusionModel(num_classes=len(dataset.class_to_idx))
train_model(model, train_loader, val_loader, DEVICE)

# --- EVALUATION ---
model.load_state_dict(torch.load('best_model.pt'))
model.eval()

score_preds, feature_preds, final_preds, targets = [], [], [], []
with torch.no_grad():
    for iris, vein, labels in val_loader:
        iris, vein, labels = iris.to(DEVICE), vein.to(DEVICE), labels.to(DEVICE)
        final_out, score_out, feature_out = model(iris, vein, return_all=True)
        score_preds.extend(score_out.argmax(dim=1).cpu().numpy())
        feature_preds.extend(feature_out.argmax(dim=1).cpu().numpy())
        final_preds.extend(final_out.argmax(dim=1).cpu().numpy())
        targets.extend(labels.cpu().numpy())

print_metrics(targets, score_preds, "Score-Level Fusion")
print_metrics(targets, feature_preds, "Feature-Level Fusion")
print_metrics(targets, final_preds, "Final Averaged Output")


